### 밑바닥부터 시작하는 딥러닝 1

|목차|velog 정리|
|:--|:--:|
|1. 헬로 파이썬|[📒](https://velog.io/@bbirong/1%EC%9E%A5.-%ED%97%AC%EB%A1%9C-%ED%8C%8C%EC%9D%B4%EC%8D%AC)|
|2. 퍼셉트론|[📒](https://velog.io/@bbirong/2%EC%9E%A5.-%ED%8D%BC%EC%85%89%ED%8A%B8%EB%A1%A0-Perceptron)|
|3. 신경망|[📒](https://velog.io/@bbirong/1-3.-%EC%8B%A0%EA%B2%BD%EB%A7%9D-v18d5g66)|
|4. 신경망 학습|[📒](https://velog.io/@bbirong/%EB%B0%91%EB%94%A5-1-4.-%EC%8B%A0%EA%B2%BD%EB%A7%9D-%ED%95%99%EC%8A%B5)|
|5. 오차역전파법|[📒](https://velog.io/write?id=ec9c17d7-45f0-4be2-a8d0-6d410d50a80a)|
|6. 학습 관련 기술들|[📒](https://velog.io/@bbirong/%EB%B0%91%EB%94%A5-6%EC%9E%A5.-%ED%95%99%EC%8A%B5-%EA%B4%80%EB%A0%A8-%EA%B8%B0%EC%88%A0%EB%93%A4)|
|7. 합성곱 신경망 (CNN)|[📒](https://velog.io/@bbirong/%EB%B0%91%EB%94%A5-7%EC%9E%A5.-%ED%95%A9%EC%84%B1%EA%B3%B1-%EC%8B%A0%EA%B2%BD%EB%A7%9DCNN)|
|8. 딥러닝||
|Appendix) Softmax-with-Loss 계층의 계산 그래프|[📒](https://velog.io/@bbirong/%EB%B0%91%EB%94%A5-%EB%B6%80%EB%A1%9D-A.-Softmax-with-Loss-%EA%B3%84%EC%B8%B5%EC%9D%98-%EA%B3%84%EC%82%B0-%EA%B7%B8%EB%9E%98%ED%94%84)|

---

### 밑바닥부터 시작하는 딥러닝 2

|목차|velog 정리|
|:--|:--:|
|1. 신경망 복습||
|2. 자연어와 단어의 분산 표현||
|3. word2vec||
|4. word2vec 속도 개선||
|5. 순환 신경망(RNN)||
|6. 게이트가 추가된 RNN||
|7. RNN을 사용한 문장 생성||
|8. 어텐션||
|Appendix) 시그모이드 함수와 tanh 함수의 미분||
|Appendix) WordNet 맛보기||
|Appendix) GRU||

